{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb79d8bd",
   "metadata": {},
   "source": [
    "The AdjointSecondOrderODEModel seeks to infer the forcing functon of a linear second order differential equation of the form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial u}{\\partial t} + p_1\\cdot\\nabla u -\\nabla \\cdot (p_2 \\nabla u)=\\zeta \\mbox{ in } \\mathcal{X}\\times [0,T]\n",
    "\\end{equation}\n",
    "with initial conditions:\n",
    "\n",
    "\\begin{equation}\n",
    "g(u(0),p)=u(0)=0\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "k(u_x,u_y,p)=\\nabla_{n}u=0\n",
    "\\end{equation}\n",
    "on the boundary.\n",
    "\n",
    "The forcing function, $\\zeta$ is approximated using Random Fourier Features so that\n",
    "\n",
    "\\begin{equation}\n",
    "\\zeta(x,y,t)\\sim \\sum_{i=1}^{M}\\phi_i(x,y,t)z_i\n",
    "\\end{equation}\n",
    "\n",
    "$\\zeta$ is then inferred using the adjoint method as in Gahungu et al. (2022).\n",
    "\n",
    "Additionally, we seek the gradient of some cost function $F=\\int_0^T\\int_0^X\\int_0^Yf(u,p,x,y,t)dydxdt$ (which measures the quality of our inference) with respect to the parameters $p={(p_{11},p_{12},p_2})$. To calculate this we follow the methods described in Andrew Bradley's adjoint tutorial (Bradley, 2009). \n",
    "\n",
    "First we set \n",
    "\\begin{equation}\n",
    "h(u,u_t,u_x,u_y,u_{xx},u_{yy},p,x,y,t) = \\frac{\\partial u}{\\partial t} + p_1\\cdot\\nabla u -\\nabla \\cdot (p_2 \\nabla u)-\\zeta\n",
    "\\end{equation}\n",
    "so that $h(u,u_t,u_x,u_y,u_{xx},u_{yy},p,x,y,t)=0$.\n",
    "subject to $g$ and $k$. \n",
    "\n",
    "We establish the lagrangian:\n",
    "\n",
    "\\begin{equation}\n",
    "   L =\\int_0^T f(u,p,x,y,t)+ \\lambda^T(h(u,u_t,u_x,u_y,u_{xx},u_{yy},p,x,y,t)) dt + \\mu^Tg(s(0),p)+\\nu^Tk(k(u_x,u_y,p),p) \n",
    "\\end{equation}\n",
    "\n",
    "Taking the total derivative with respect to p, integrating by parts and collecting terms (and those that are zero in our specific case) gives\n",
    "\\begin{equation}\n",
    "d_mL=\\int_0^T\\int_0^X\\int_0^Y\\lambda^T\\delta_phdydxdt \n",
    "\\end{equation}\n",
    "subject to\n",
    "\\begin{equation}\n",
    "\\delta_s f - \\frac{\\partial \\lambda^T}{\\partial t} - p_1\\cdot\\nabla \\lambda^T -\\nabla \\cdot (p_2 \\nabla \\lambda^T)=0\n",
    "\\end{equation}\n",
    "\n",
    "where \n",
    "\\begin{equation}\n",
    "\\delta_ph = \\left(\\frac{\\delta u}{\\delta x},\\frac{\\delta u}{\\delta y},-\\frac{\\delta^2 u}{\\delta x^2}-\\frac{\\delta^2 u}{\\delta y^2}\\right).\n",
    "\\end{equation}\n",
    "\n",
    "We choose the cost function \n",
    "\\begin{equation}\n",
    "F =\\int_0^T\\int_0^X\\int_0^Y f(s,p,x,y,t)dt = \\int^T_0\\frac{1}{M}\\sum_{i=0}^M (s(t)-z(t))^2\\delta(y-y_i)\\delta(x-x_i)\\delta(t-t_i)dydxdt,\n",
    "\\end{equation}\n",
    "where\n",
    "\\begin{equation}\n",
    "z(t)=\\begin{cases}\n",
    "z_i \\ \\mathrm{ if } \\ t=t_i,x=x_i,y=y_i \\\\ 0 \\ \\mathrm{ o.w.}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "Here, $z_i$ are our observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345df7c8",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "931b954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal #For later example\n",
    "\n",
    "#advectionGP\n",
    "\n",
    "from advectionGP.models import AdjointAdvectionDiffusionModel as PDEModel\n",
    "\n",
    "from advectionGP.wind import WindSimple#Wind model\n",
    "\n",
    "\n",
    "from advectionGP.sensors import FixedSensorModel #Builds sensor arrays to generate data for foward model or to generate observations for comparison\n",
    "from advectionGP.kernels import EQ #Generates exponentiated quadratic kernel approximation\n",
    "from advectionGP.test import TestKernels #Unit test model\n",
    "\n",
    "\n",
    "#Plotting tools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6586cdc",
   "metadata": {},
   "source": [
    "# Establish sensor array and generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d17b4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sensor locations for training data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(1,9,10) # lower time\n",
    "xloc=np.linspace(1,9,5) # x locations\n",
    "yloc=np.linspace(1,9,5) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "X= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "X[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] #lower time\n",
    "X[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1] # x location\n",
    "X[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2] # ylocation\n",
    "X[:,1] = X[:,0]+0.1 # upper time\n",
    "\n",
    "sensors = FixedSensorModel(X,0.1) # establish sensor model arguments are sensor locations and spatial averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df30c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_0 = 0.001 #Diffusion\n",
    "R=0.1\n",
    "noiseSD = 0.05 #Observation noise\n",
    "N_feat=2000 # number of features used to approximate ground truth GP\n",
    "boundary = ([0,0,0],[10,10,10])# corners of the grid - in units of space\n",
    "k = EQ(2, 2.0) # generate EQ kernel arguments are lengthscale and variance\n",
    "res = [50,50,50] # grid size for time, x and y\n",
    "\n",
    "\n",
    "u1 = 0.001\n",
    "u2 = 0.001\n",
    "windmodel=WindSimple(u1,u2) # establish fixed wind model\n",
    "m = PDEModel(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,windmodel=windmodel,k_0=k_0) #initiate PDE model to build concentration\n",
    "\n",
    "dt,dx,dy,dx2,dy2,Nt,Nx,Ny = m.getGridStepSize() # useful numbers!\n",
    "\n",
    "z=np.random.normal(0,1.0,N_feat) # Generate z to compute source\n",
    "\n",
    "sourceGT=(m.computeSourceFromPhi(z))# Compute source\n",
    "\n",
    "#sourceGT = np.zeros(m.resolution)\n",
    "#sourceGT[:,20:30,20:30]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3048a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "concTrain=m.computeConcentration(sourceGT) # Compute concentration - runs advection diffusion forward model\n",
    "yTrain= m.computeObservations(addNoise=True) # Compute observations with noise uses m.sensormodel for observation locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2825937f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Adjoints...\n",
      "249/250 \n",
      "Calculating Phis...\n",
      "999/1000 \n"
     ]
    }
   ],
   "source": [
    "N_feat =1000 #Number of features used to infer the source\n",
    "k1 = EQ(2, 2.0) \n",
    "k2 = EQ(2, 2.0) \n",
    "\n",
    "mPDE = PDEModel(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k1,sensormodel=sensors,windmodel=windmodel,k_0=k_0) #Initiate new model for inference\n",
    "regressPDE = mPDE.computeModelRegressors() # Compute regressor matrix\n",
    "meanZPDE, covZPDE = mPDE.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "sourceInfer = mPDE.computeSourceFromPhi(meanZPDE) # Generates estimated source using inferred distributio\n",
    "concInfer = mPDE.computeConcentration(sourceInfer)\n",
    "yOut = mPDE.computeObservations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b08e4",
   "metadata": {},
   "source": [
    "# Functions to calculate cost $f$ using hill function approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8547ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcost(obs,X,conc,model):\n",
    "    c=np.zeros(model.resolution)\n",
    "    M=len(obs)\n",
    "    eps=0.1\n",
    "    for i,loc in enumerate(X[:,(0,2,3)]):\n",
    "        c[tuple(model.getGridCoord(loc))] = 2*(conc[tuple(model.getGridCoord(loc))]-obs[i])*(1/M)\n",
    "    return c\n",
    "\n",
    "def cost(obs,X,conc,model):\n",
    "    c=np.zeros(model.resolution)\n",
    "    M=len(obs)\n",
    "    eps=0.1\n",
    "    for i,loc in enumerate(X[:,(0,2,3)]):\n",
    "        c[tuple(model.getGridCoord(loc))] = ((conc[tuple(model.getGridCoord(loc))]-obs[i])**2)*(1/M)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e329c5",
   "metadata": {},
   "source": [
    "# Function to calculate adjoint equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aebf416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradientAdjoint(dcost,model):\n",
    "        \"\"\"\n",
    "        Runs the backward PDE (adjoint problem)\n",
    "        Gets called for an observation instance (H).\n",
    "        (v is the result of the adjoint operation)\n",
    "        \"\"\"\n",
    "        dt,dx,dy,dx2,dy2,Nt,Nx,Ny = model.getGridStepSize()\n",
    "\n",
    "        v=np.zeros(((Nt,Nx,Ny)))\n",
    "        v[-1,:,:]=0.0\n",
    "        u=model.u\n",
    "        k_0=model.k_0\n",
    "        for i in range(1,Nt): #TODO might be better to rewrite as range(Nt-1,1,-1)...\n",
    "    #Corner BCs   \n",
    "            v[-i-1,0,0]=v[-i,0,0]+dt*(-dcost[-i,0,0]) # BC at x=0, y=0\n",
    "            v[-i-1,Nx-1,Ny-1]=v[-i,Nx-1,Ny-1]+dt*(-dcost[-i,Nx-1,Ny-1]) # BC at x=xmax, y=ymax\n",
    "            v[-i-1,0,Ny-1]=v[-i,0,Ny-1]+dt*( -dcost[-i,0,Ny-1]) # BC at x=0, y=ymax\n",
    "            v[-i-1,Nx-1,0]=v[-i,Nx-1,0]+dt*( -dcost[-i,Nx-1,0]) # BC at x=xmax, y=0\n",
    "\n",
    "\n",
    "    #Edge BCs   \n",
    "            v[-i-1,Nx-1,1:Ny-1]=v[-i,Nx-1,1:Ny-1]+dt*(-dcost[-i,Nx-1,1:Ny-1] +u[1][-i,Nx-1,1:Ny-1]*(v[-i,Nx-1,2:Ny]-v[-i,Nx-1,0:Ny-2] )/(2*dy) +k_0*(v[-i,Nx-1,2:Ny]-2*v[-i,Nx-1,1:Ny-1]+v[-i,Nx-1,0:Ny-2])/dy2) # BC at x=xmax        \n",
    "            v[-i-1,0,1:Ny-1]=v[-i,0,1:Ny-1]+dt*(-dcost[-i,0,1:Ny-1]+u[1][-i,0,1:Ny-1]*(v[-i,0,2:Ny]-v[-i,0,0:Ny-2] )/(2*dy) +k_0*(v[-i,0,2:Ny]-2*v[-i,0,1:Ny-1]+v[-i,0,0:Ny-2])/dy2 ) # BC at x=0\n",
    "\n",
    "            v[-i-1,1:Nx-1,0]=v[-i,1:Nx-1,0]+dt*(   -dcost[-i,1:Nx-1,0]+u[0][-i,1:Nx-1,0]*(v[-i,2:Nx,0]-v[-i,0:Nx-2,0] )/(2*dx) +k_0*(v[-i,2:Nx,0]-2*v[-i,1:Nx-1,0]+v[-i,0:Nx-2,0])/dx2  )# BC at y=0\n",
    "            v[-i-1,1:Nx-1,Ny-1]=v[-i,1:Nx-1,Ny-1]+dt*(-dcost[-i,1:Nx-1,Ny-1]+u[0][-i,1:Nx-1,Ny-1]*(v[-i,2:Nx,Ny-1]-v[-i,0:Nx-2,Ny-1] )/(2*dx)+k_0*(v[-i,2:Nx,Ny-1]-2*v[i,1:Nx-1,Ny-1]+v[-i,0:Nx-2,Ny-1])/dx2) # BC at y=ymax\n",
    "\n",
    "    #Internal calculation (not on the boundary)\n",
    "            v[-i-1,1:Nx-1,1:Ny-1]=v[-i,1:Nx-1,1:Ny-1] +dt*( -dcost[-i,1:Nx-1,1:Ny-1]+u[0][-i,1:Nx-1,1:Ny-1]*(v[-i,2:Nx,1:Ny-1]-v[-i,0:Nx-2,1:Ny-1])/(2*dx) +u[1][-i,1:Nx-1,1:Ny-1]*(v[-i,1:Nx-1,2:Ny]-v[-i,1:Nx-1,0:Ny-2] )/(2*dy)+k_0*(v[-i,2:Nx,1:Ny-1]-2*v[-i,1:Nx-1,1:Ny-1]  +v[-i,0:Nx-2,1:Ny-1])/dx2+k_0*(v[-i,1:Nx-1,2:Ny]-2*v[-i,1:Nx-1,1:Ny-1]  +v[-i,1:Nx-1,0:Ny-2])/dy2 )\n",
    "        return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc6244",
   "metadata": {},
   "source": [
    "# Function to calculate the Lagrangian derivative, the cost and the derivative of the cost for a given $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dcb3873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_mL(u1,u2,k_0,model,obs,tloc,source):\n",
    "    model.windmodel=WindSimple(u1,u2)\n",
    "    model.u=model.windmodel.getu(model)\n",
    "    model.k_0=k_0\n",
    "    dt,dx,dy,dx2,dy2,Nt,Nx,Ny = model.getGridStepSize()\n",
    "    #regressPDE = mPDE.computeModelRegressors() # Compute regressor matrix\n",
    "    #meanZPDE, covZPDE = mPDE.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "    #source = mPDE.computeSourceFromPhi(meanZPDE) # Generates estimated source using inferred distributio\n",
    "    conc=model.computeConcentration(source)\n",
    "    dudx=np.gradient(conc,dx,axis=1)\n",
    "    dudy=np.gradient(conc,dy,axis=2)\n",
    "    d2udx2 = np.gradient(dudx,dx,axis=1)\n",
    "    d2udy2 = np.gradient(dudy,dy,axis=2)\n",
    "\n",
    "    dmH=np.array([dudx,dudy,-d2udx2-d2udy2])\n",
    "    \n",
    "    dc=dcost(obs,tloc,conc,model)\n",
    "    c=cost(obs,tloc,conc,model)\n",
    "    #print(np.sum((c/2)**2))\n",
    "    L_m=np.zeros(3)\n",
    "    for i, dmHi in enumerate(dmH):\n",
    "        integrand = computeGradientAdjoint(dc,model)*dmHi\n",
    "    #L_m = np.trapz(integrand,dx=dt)\n",
    "        L_m[i] = np.sum(integrand)*dt*dx*dy\n",
    "    return L_m, dc,c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918703d1",
   "metadata": {},
   "source": [
    "# Naive gradient descent (output used to test gradient calculation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbca91e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "reps = 1000\n",
    "p=np.zeros((3,reps))\n",
    "d=np.zeros((3,reps-1))\n",
    "dTest=np.zeros((3,reps-1))\n",
    "dTest2=np.zeros((3,reps-1))\n",
    "Fc=np.zeros((3,reps-1))\n",
    "Dc=np.zeros((3,reps-1))\n",
    "p[:,0]=np.array([u1,u2,k_0])+np.random.normal(0,0.001,3)\n",
    "eps2=1e-8\n",
    "for i in range(reps-1):\n",
    "    [u11,u21,k_01] = p[:,i]\n",
    "    print(i)\n",
    "    dmL, dc,c=d_mL(u11,u21,k_01,mPDE,yTrain,X,sourceInfer)\n",
    "    d[:,i]=dmL\n",
    "    p[:,i+1]=p[:,i]-0.001*dmL\n",
    "    Fc[:,i] = np.sum(c)*dt*dx*dy\n",
    "    Dc[:,i] = np.sum(((1/100)*(dc*100/2)**2))*dt*dx*dy\n",
    "    dmL2, dc2,c2=d_mL(u11+eps2,u21,k_01,mPDE,yTrain,X,sourceInfer)\n",
    "    dmL3, dc3,c3=d_mL(u11,u21+eps2,k_01,mPDE,yTrain,X,sourceInfer)\n",
    "    dmL4, dc4,c4=d_mL(u11,u21,k_01+eps2,mPDE,yTrain,X,sourceInfer)\n",
    "    dmL5, dc5,c5=d_mL(u11-eps2,u21,k_01,mPDE,yTrain,X,sourceInfer)\n",
    "    dmL6, dc6,c6=d_mL(u11,u21-eps2,k_01,mPDE,yTrain,X,sourceInfer)\n",
    "    dmL7, dc7,c7=d_mL(u11,u21,k_01-eps2,mPDE,yTrain,X,sourceInfer)\n",
    "    \n",
    "    dTest[:,i] = (np.array((np.sum((c2))*dt*dx*dy-np.sum((c5))*dt*dx*dy,np.sum((c3))*dt*dx*dy-np.sum((c6))*dt*dx*dy,np.sum((c4))*dt*dx*dy-np.sum((c7))*dt*dx*dy)))/(2*eps2)\n",
    "    dTest2[:,i] = ((np.sum((c2))*dt*dx*dy,np.sum((c3))*dt*dx*dy,np.sum(c4)*dt*dx*dy)-(np.sum(c)*dt*dx*dy))/(eps2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0,0.0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b092ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(p.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14286170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dTest.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b6b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Fc.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015d0a0",
   "metadata": {},
   "source": [
    "### Functions for cost and derivative for use with scipy optimiser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe3d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullCost(x,model,obs,tloc,source):\n",
    "    #model.k_0=x[2]\n",
    "    model.windmodel=WindSimple(x[0],x[1])\n",
    "    model.u=model.windmodel.getu(model)\n",
    "    model.k_0=x[2]\n",
    "    dt,dx,dy,dx2,dy2,Nt,Nx,Ny = model.getGridStepSize()\n",
    "    conc=model.computeConcentration(source)\n",
    "\n",
    "    c1=cost(obs,tloc,conc,model)\n",
    "    \n",
    "    c = np.sum(c1)*dt*dx*dy\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f838d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FullDeriv(x,model,obs,tloc,source):\n",
    "    model.windmodel=WindSimple(x[0],x[1])\n",
    "    model.u=model.windmodel.getu(model)\n",
    "    model.k_0=x[2]\n",
    "    dt,dx,dy,dx2,dy2,Nt,Nx,Ny = model.getGridStepSize()\n",
    "    conc=model.computeConcentration(source)\n",
    "    dudx=np.gradient(conc,dx,axis=1)\n",
    "    dudy=np.gradient(conc,dy,axis=2)\n",
    "    d2udx2 = np.gradient(dudx,dx,axis=1)\n",
    "    d2udy2 = np.gradient(dudy,dy,axis=2)\n",
    "\n",
    "    dmH=np.array([dudx,dudy,-d2udx2-d2udy2])\n",
    "    \n",
    "    dc=dcost(obs,tloc,conc,model)\n",
    "    c=cost(obs,tloc,conc,model)\n",
    "    #print(np.sum((c/2)**2))\n",
    "\n",
    "    #L_m = np.trapz(integrand,dx=dt)\n",
    "    L_m=np.zeros(3)\n",
    "    for i, dmHi in enumerate(dmH):\n",
    "        integrand = computeGradientAdjoint(dc,model)*dmHi\n",
    "    #L_m = np.trapz(integrand,dx=dt)\n",
    "        L_m[i] = np.sum(integrand)*dt*dx*dy\n",
    "    return L_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d84bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [0.011,0.011,0.011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c07c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(FullCost, x0, method='bfgs', jac=FullDeriv,args=(mPDE,yTrain,X,sourceInfer),options={'disp': True},tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f89a132",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "317fb2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.018752\n",
      "         Iterations: 7\n",
      "         Function evaluations: 76\n",
      "         Gradient evaluations: 59\n",
      "[0.06162126 0.03910621 0.02107232]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.051620\n",
      "         Iterations: 6\n",
      "         Function evaluations: 64\n",
      "         Gradient evaluations: 46\n",
      "[0.08649803 0.0447028  0.04447528]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.134327\n",
      "         Iterations: 1\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 7\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "999/1000 \n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.166642\n",
      "         Iterations: 0\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 3\n",
      "[0.08747289 0.0433663  0.05262178]\n",
      "Calculating Adjoints...\n",
      "74/75 \n",
      "Calculating Phis...\n",
      "791/1000 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-584db673a943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmInfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmInfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmInfer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmInfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmInfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeModelRegressors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Compute regressor matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mmeanZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcovZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmInfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeZDistribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Infers z vector mean and covariance using regressor matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msourceInfer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmInfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeSourceFromPhi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeanZ\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Generates estimated source using mean of the inferred distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris\\documents\\github\\advectiongp\\advectionGP\\models.py\u001b[0m in \u001b[0;36mcomputeModelRegressors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d/%d \\r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m#phi * v, --> scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2245\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2247\u001b[1;33m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[0;32m   2248\u001b[0m                           initial=initial, where=where)\n\u001b[0;32m   2249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x=result.x\n",
    "mInfer=mPDE\n",
    "#mInfer = PDEModel(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k1,sensormodel=sensors,k_0=-1,u=x[0],eta=x[1]) #Initiate new model for inference\n",
    "for i in range(50):\n",
    "    mInfer.windmodel=WindSimple(x[0],x[1])\n",
    "    mInfer.u=mInfer.windmodel.getu(mInfer)\n",
    "    mInfer.k_0=x[2]\n",
    "    mInfer.computeModelRegressors() # Compute regressor matrix \n",
    "    meanZ, covZ = mInfer.computeZDistribution(yTrain) # Infers z vector mean and covariance using regressor matrix\n",
    "    sourceInfer = mInfer.computeSourceFromPhi(meanZ) # Generates estimated source using mean of the inferred distribution\n",
    "    concInfer=mInfer.computeConcentration(sourceInfer) # Generates estimated concentration from inferred source\n",
    "    result = minimize(FullCost, x, method='BFGS', jac=FullDeriv,args=(mInfer,yTrain,X,sourceInfer),options={'disp': True},tol=1e-8)\n",
    "    x = result.x\n",
    "    print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb55c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f049f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
