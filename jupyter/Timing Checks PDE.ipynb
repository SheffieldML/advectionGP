{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95466d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "\n",
    "#numpy\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal #For later example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#advectionGP\n",
    "from advectionGP.models import AdjointAdvectionDiffusionReactionModel as PDEModel #Model module builds basic parts of the PDE problem, combines other classes into full model\n",
    "from advectionGP.models import AdjointSimpleODEModel as ODEModel #Model module builds basic pa\n",
    "from advectionGP.sensors import FixedSensorModel #Builds sensor arrays to generate data for foward model or to generate observations for comparison\n",
    "from advectionGP.kernels import EQ #Generates exponentiated quadratic kernel approximation\n",
    "from advectionGP.test import TestKernels #Unit test model\n",
    "from advectionGP.wind import WindFixU #Wind model\n",
    "\n",
    "#Plotting tools\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "# GPy: Gaussian processes library\n",
    "import GPy\n",
    "\n",
    "import scipy\n",
    "\n",
    "#GPyOpt\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58044c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sensor locations for training data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(1,8,4) # lower time\n",
    "xloc=np.linspace(2,8,5) # x locations\n",
    "yloc=np.linspace(2,8,5) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "X= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "X[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] #lower time\n",
    "X[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1] # x location\n",
    "X[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2] # ylocation\n",
    "X[:,1] = X[:,0]+1 # upper time\n",
    "\n",
    "XGP= np.zeros((sensN*obsN,3))\n",
    "XGP[:,0] = (X[:,0]+X[:,1])/2\n",
    "XGP[:,1] = X[:,2]\n",
    "XGP[:,2] = X[:,3] \n",
    "\n",
    "\n",
    "\n",
    "sensors = FixedSensorModel(X,1) # establish sensor model arguments are sensor locations and spatial averaging\n",
    "\n",
    "# generate sensor locations for test data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(2,9,5) # lower time\n",
    "xloc=np.linspace(1.5,8.5,4) # x locations\n",
    "yloc=np.linspace(1.5,8.5,4) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "Xtest= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "Xtest[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] \n",
    "Xtest[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1]\n",
    "Xtest[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2]\n",
    "Xtest[:,1] = Xtest[:,0]+1\n",
    "\n",
    "XGPtest= np.zeros((sensN*obsN,3))\n",
    "XGPtest[:,0] = (Xtest[:,0]+Xtest[:,1])/2\n",
    "XGPtest[:,1] = Xtest[:,2]\n",
    "XGPtest[:,2] = Xtest[:,3]\n",
    "\n",
    "sensorsTest = FixedSensorModel(Xtest,1) # establish sensor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd1d180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_0 = 0.01 #Diffusion\n",
    "R=0.1\n",
    "noiseSD = 0.05 #Observation noise\n",
    "N_feat=2000 # number of features used to approximate ground truth GP\n",
    "boundary = ([0,0,0],[10,10,10])# corners of the grid - in units of space\n",
    "k = EQ(2, 2.0) # generate EQ kernel arguments are lengthscale and variance\n",
    "res = [50,30,30] # grid size for time, x and y\n",
    "wind=np.cos(np.linspace(0,6*np.pi,res[1]))*0.5\n",
    "u=[]\n",
    "u.append(np.ones(res)*0.01) #x direction wind\n",
    "u.append(np.ones(res)*0.01) # y direction wind\n",
    "windmodel=WindFixU(u)\n",
    "#u.append(np.ones(res)*0.1) #x direction wind\n",
    "#u.append(np.ones(res)*0.1) # y direction wind\n",
    "m = PDEModel(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,windmodel=windmodel,k_0=k_0,R=R) #initiate PDE model to build concentration\n",
    "\n",
    "dt,dx,dy,dx2,dy2,Nt,Nx,Ny = m.getGridStepSize() # useful numbers!\n",
    "\n",
    "z=np.random.normal(0,1.0,N_feat) # Generate z to compute source\n",
    "sourceGT=(m.computeSourceFromPhi(z))# Compute source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd54d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "concTrain=m.computeConcentration(sourceGT) # Compute concentration - runs advection diffusion forward model\n",
    "yTrain= m.computeObservations() # Compute observations with noise uses m.sensormodel for observation locations\n",
    "\n",
    "m.sensormodel=sensorsTest\n",
    "yTest= m.computeObservations() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e38b9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 = EQ(2, 2.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2578531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "3.32 s ± 181 ms per loop (mean ± std. dev. of 4 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 4 -n 10\n",
    "mPDE = PDEModel(resolution=res,boundary=boundary,N_feat=100,noiseSD=noiseSD,kernel=k2,sensormodel=sensors,windmodel=windmodel,k_0=k_0,R=R) #Initiate new model for inference\n",
    "regressPDE = mPDE.computeModelRegressors() # Compute regressor matrix\n",
    "meanZPDE, covZPDE = mPDE.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "sourcePDE = mPDE.computeSourceFromPhi(meanZPDE) # Generates estimated source using inferred distributio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "156bb554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "total_its =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bdf4affe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "12\n",
      "12\n",
      "12\n",
      "11\n",
      "12\n",
      "9\n",
      "9\n",
      "7\n",
      "8\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "8\n",
      "10\n",
      "11\n",
      "13\n",
      "12\n",
      "12\n",
      "12\n",
      "11\n",
      "11\n",
      "9\n",
      "10\n",
      "9\n",
      "8\n",
      "10\n",
      "8\n",
      "10\n",
      "11\n",
      "8\n",
      "11\n",
      "13\n",
      "13\n",
      "12\n",
      "3.5 s ± 25.2 ms per loop (mean ± std. dev. of 4 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 4 -n 10\n",
    "N_feat = 100\n",
    "k2 = EQ(2, 2.0)\n",
    "sigmaMCMC=0.005\n",
    "out2 = []\n",
    "var = np.ones(len(yTrain))*noiseSD**2\n",
    "accept = 0 \n",
    "start_time2 = time.time()\n",
    "t_end = time.time() +3.32\n",
    "iters = 0\n",
    "ObsN=75\n",
    "mMCMC = PDEModel(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k2,sensormodel=sensors,windmodel=windmodel,k_0=k_0,R=R) #initiate PDE model to build concentration\n",
    "#zCur=np.random.normal(0,1.0,N_feat) # Generate z to compute source\n",
    "zCur=np.ones(N_feat)\n",
    "source = mMCMC.computeSourceFromPhi(zCur) # Generates estimated source using inferred distribution\n",
    "conc=mMCMC.computeConcentration(source) # Compute test concentration\n",
    "yMCMC= mMCMC.computeObservations() # Compute observations with noise\n",
    "#llObsCur = -0.5*np.sum((np.square(np.subtract(yTrain,yMCMC))/(noiseSD**2)))-0.5*ObsN*np.log(noiseSD**2)-0.5*ObsN*np.log(2*np.pi)\n",
    "logPiCur = -np.inf\n",
    "llObsCur = 0\n",
    "iterations=20000\n",
    "#out2.append(zCur)\n",
    "#for zi in zCur:\n",
    "#    logPriorCur += np.log(scipy.stats.norm(0, 1).pdf(zi))\n",
    "\n",
    "for i in range(iterations):\n",
    "    zCan = zCur + np.random.normal(0,sigmaMCMC,N_feat)\n",
    "    source = mMCMC.computeSourceFromPhi(zCan) # Generates estimated source using inferred distribution\n",
    "    concCan=mMCMC.computeConcentration(source) # Compute test concentration\n",
    "    yCan= mMCMC.computeObservations() # Compute observations with noise\n",
    "    llObsCan = -0.5*np.sum((np.square(np.subtract(yTrain,yCan))/(noiseSD**2)))-0.5*ObsN*np.log(noiseSD**2)-0.5*ObsN*np.log(2*np.pi)\n",
    "    logPriorCan = 0\n",
    "    for j in zCan:\n",
    "        logPriorCan += np.log(scipy.stats.norm(0, 1).pdf(j))\n",
    "\n",
    "    logPiCan = llObsCan + logPriorCan\n",
    "    #logPiCur = llObsCur + logPriorCur\n",
    "    #print(logPiCan,logPiCur)\n",
    "    u = np.random.uniform(0,1)\n",
    "\n",
    "    if np.log(u) < logPiCan - logPiCur:\n",
    "        zCur = zCan\n",
    "        #logPriorCur = logPriorCan\n",
    "        logPiCur = logPiCan\n",
    "        accept += 1###\n",
    "    out2.append(zCur)\n",
    "    iters +=1\n",
    "    if time.time() > t_end:\n",
    "        break \n",
    "total_its.append(np.array(iters))        \n",
    "print(iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0ced28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.625"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(total_its)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "433a12c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7419457511644845"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(total_its)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b2920",
   "metadata": {},
   "source": [
    "# Timing ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418cf358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal #For later example\n",
    "\n",
    "#advectionGP\n",
    "from advectionGP.models import AdjointSecondOrderODEModel as Model #Model module builds basic parts of the ODE problem, combines other classes into full model\n",
    "\n",
    "'''To use other models in the class, such as the Advection Diffusion Reaction model, \n",
    "replace \"AdjointSecondOrderODEModel\" in the line above with \"AdjointAdvectionDiffusionReaction\" model\n",
    "and adjust parameters as appropriate'''\n",
    "\n",
    "from advectionGP.sensors import FixedSensorModel #Builds sensor arrays to generate data for foward model or to generate observations for comparison\n",
    "from advectionGP.kernels import EQ #Generates exponentiated quadratic kernel approximation\n",
    "from advectionGP.test import TestKernels #Unit test model\n",
    "\n",
    "\n",
    "#Plotting tools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec3bea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg=0.1 # time that an observation is taken for\n",
    "tlocL = np.linspace(0,9.9,100) # observation start times\n",
    "X= np.zeros((len(tlocL),2)) # initiate X\n",
    "# Build sensor locations\n",
    "X[:,0] = tlocL #lower time\n",
    "X[:,1] = X[:,0]+avg # upper time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "916dc625",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensors = FixedSensorModel(X,0) # establish sensor model arguments are sensor locations and spatial averaging (not applicable in 1D case so set to 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a04ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_0 = -0.5 #Diffusion coefficient\n",
    "u=1\n",
    "eta=5\n",
    "noiseSD = 0.05 #Observation noise\n",
    "N_feat=2000 # number of features used to approximate ground truth GP\n",
    "boundary = ([0],[10])# edges of the grid - in units of time\n",
    "kForward = EQ(0.6, 4.0) # generate EQ kernel arguments are lengthscale and variance\n",
    "res = [100] # grid size for time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b721d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=kForward,sensormodel=sensors,k_0=k_0,u=u,eta=eta) #initiate PDE model to build concentration\n",
    "\n",
    "dt,dt2,Nt = m.getGridStepSize() # useful numbers!\n",
    "\n",
    "z=np.random.normal(0,1.0,N_feat) # Generate z to compute source\n",
    "sourceGT=m.computeSourceFromPhi(z)# Compute ground truth source by approximating GP\n",
    "#sourceGT = np.ones(m.resolution)  # Example constant source\n",
    "concTrain=m.computeConcentration(sourceGT) # Compute concentration - runs ODE forward model\n",
    "yTrain= m.computeObservations() # Compute observations with noise uses m.sensormodel for observation locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d67f51dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "99/100 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "569 ms ± 72.5 ms per loop (mean ± std. dev. of 4 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 4 -n 10\n",
    "N_feat =100 #Number of features used to infer the source\n",
    "kInverse = EQ(0.6, 4) # Initiate kernel for inverse problem\n",
    "mInfer = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=kInverse,sensormodel=sensors,k_0=k_0,u=u,eta=eta) #Initiate new model for inference\n",
    "mInfer.computeModelRegressors() # Compute regressor matrix \n",
    "meanZ, covZ = mInfer.computeZDistribution(yTrain) # Infers z vector mean and covariance using regressor matrix\n",
    "sourceInfer = mInfer.computeSourceFromPhi(meanZ) # Generates estimated source using mean of the inferred distribution\n",
    "concInfer=m.computeConcentration(sourceInfer) # Generates estimated concentration from inferred source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b863eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88190797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    k2 = EQ(2, 2.0)\n",
    "    sigmaMCMC=0.005\n",
    "    out2 = []\n",
    "    var = np.ones(len(yTrain))*noiseSD**2\n",
    "    accept = 0 \n",
    "    start_time2 = time.time()\n",
    "    t_end = time.time() +0.562\n",
    "    iters = 0\n",
    "    ObsN=50\n",
    "\n",
    "    mMCMC = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k2,sensormodel=sensors,k_0=k_0,u=u,eta=eta) #Initiate new model for inference\n",
    "    #zCur=np.random.normal(0,1.0,N_feat) # Generate z to compute source\n",
    "    zCur=np.ones(N_feat)\n",
    "    source = mMCMC.computeSourceFromPhi(zCur) # Generates estimated source using inferred distribution\n",
    "    conc=mMCMC.computeConcentration(source) # Compute test concentration\n",
    "    yMCMC= mMCMC.computeObservations() # Compute observations with noise\n",
    "    #llObsCur = -0.5*np.sum((np.square(np.subtract(yTrain,yMCMC))/(noiseSD**2)))-0.5*ObsN*np.log(noiseSD**2)-0.5*ObsN*np.log(2*np.pi)\n",
    "    logPiCur = -np.inf\n",
    "    llObsCur = 0\n",
    "    iterations=20000\n",
    "    #out2.append(zCur)\n",
    "    #for zi in zCur:\n",
    "    #    logPriorCur += np.log(scipy.stats.norm(0, 1).pdf(zi))\n",
    "\n",
    "    for i in range(iterations):\n",
    "        zCan = zCur + np.random.normal(0,sigmaMCMC,N_feat)\n",
    "        source = mMCMC.computeSourceFromPhi(zCan) # Generates estimated source using inferred distribution\n",
    "        concCan=mMCMC.computeConcentration(source) # Compute test concentration\n",
    "        yCan= mMCMC.computeObservations() # Compute observations with noise\n",
    "        llObsCan = -0.5*np.sum((np.square(np.subtract(yTrain,yCan))/(noiseSD**2)))-0.5*ObsN*np.log(noiseSD**2)-0.5*ObsN*np.log(2*np.pi)\n",
    "        logPriorCan = 0\n",
    "        for j in zCan:\n",
    "            logPriorCan += np.log(scipy.stats.norm(0, 1).pdf(j))\n",
    "\n",
    "        logPiCan = llObsCan + logPriorCan\n",
    "        #logPiCur = llObsCur + logPriorCur\n",
    "        #print(logPiCan,logPiCur)\n",
    "        u = np.random.uniform(0,1)\n",
    "\n",
    "        if np.log(u) < logPiCan - logPiCur:\n",
    "            zCur = zCan\n",
    "            #logPriorCur = logPriorCan\n",
    "            logPiCur = logPiCan\n",
    "            accept += 1\n",
    "        out2.append(zCur)\n",
    "        iters +=1\n",
    "        if time.time() > t_end:\n",
    "            break \n",
    "\n",
    "    print(iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66f087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
