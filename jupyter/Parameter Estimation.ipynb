{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9402ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "\n",
    "\n",
    "#GPyOpt\n",
    "import GPyOpt\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "\n",
    "\n",
    "#numpy\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal #For later example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#advectionGP\n",
    "from advectionGP.models import AdjointAdvectionDiffusionReactionModel as Model #Model module builds basic parts of the PDE problem, combines other classes into full model\n",
    "from advectionGP.models import AdjointSimpleODEModel as ODEModel #Model module builds basic pa\n",
    "from advectionGP.sensors import FixedSensorModel #Builds sensor arrays to generate data for foward model or to generate observations for comparison\n",
    "from advectionGP.kernels import EQ #Generates exponentiated quadratic kernel approximation\n",
    "from advectionGP.test import TestKernels #Unit test model\n",
    "\n",
    "#Plotting tools\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27bc03",
   "metadata": {},
   "source": [
    "# Generate Observations Using Physical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0636df6",
   "metadata": {},
   "source": [
    "### Generate Training and Testing Sensor Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b11f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sensor locations for training data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(1,8,3) # lower time\n",
    "xloc=np.linspace(2,8,4) # x locations\n",
    "yloc=np.linspace(2,8,4) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "X= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "X[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] #lower time\n",
    "X[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1] # x location\n",
    "X[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2] # ylocation\n",
    "X[:,1] = X[:,0]+1 # upper time\n",
    "\n",
    "sensors = FixedSensorModel(X,1) # establish sensor model arguments are sensor locations and spatial averaging\n",
    "\n",
    "# generate sensor locations for test data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(2,9,5) # lower time\n",
    "xloc=np.linspace(1.5,7.5,4) # x locations\n",
    "yloc=np.linspace(1.5,7.5,4) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "Xtest= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "Xtest[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] \n",
    "Xtest[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1]\n",
    "Xtest[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2]\n",
    "Xtest[:,1] = Xtest[:,0]+1\n",
    "\n",
    "sensorsTest = FixedSensorModel(Xtest,1) # establish sensor model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7c7943",
   "metadata": {},
   "source": [
    "### Run Forward Model to Compute Concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c496be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be inferred\n",
    "k_0 = 0.01 #Diffusion\n",
    "R=1\n",
    "l=1.0\n",
    "sigma2=2.0\n",
    "\n",
    "\n",
    "k = EQ(l,sigma2) # generate EQ kernel arguments are lengthscale and variance\n",
    "noiseSD = 0.05 #Observation noise\n",
    "N_feat=2000 # number of features used to approximate ground truth GP\n",
    "boundary = ([0,0,0],[10,10,10])# corners of the grid - in units of space\n",
    "res = [50,30,30] # grid size for time, x and y\n",
    "wind=np.cos(np.linspace(0,6*np.pi,res[1]))*0.5\n",
    "u=[]\n",
    "#u.append(np.ones(res)*wind) #x direction wind\n",
    "#u.append(np.ones(res)*0.0) # y direction wind\n",
    "\n",
    "u.append(np.ones(res)*0.01) #x direction wind\n",
    "u.append(np.ones(res)*0.01) # y direction wind\n",
    "m = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,u=u,k_0=k_0,R=R) #initiate PDE model to build concentration\n",
    "\n",
    "dt,dx,dy,dx2,dy2,Nt,Nx,Ny = m.getGridStepSize() # useful numbers!\n",
    "\n",
    "z=np.random.normal(0,1.0,N_feat) # Generate z to compute source\n",
    "sourceGT=(m.computeSourceFromPhi(z))# Compute source\n",
    "#source[source<0]=0\n",
    "\n",
    "#source = np.zeros(m.resolution)\n",
    "##source[0,int(Nx/2)-1,int(Ny/2)-1] = 10.0\n",
    "#source[:,15:25,15:25] = 5\n",
    "#source[:,2:7,2:7] = 25\n",
    "#source[:,7:12,15:20] = 25\n",
    "#source[:,18:28,10:20] = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6455012",
   "metadata": {},
   "source": [
    "### Generate Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e90bf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concTrain=m.computeConcentration(sourceGT) # Compute concentration - runs advection diffusion forward model\n",
    "yTrain= m.computeObservations() # Compute observations with noise uses m.sensormodel for observation locations\n",
    "\n",
    "m.sensormodel=sensorsTest\n",
    "yTest= m.computeObservations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc72f1",
   "metadata": {},
   "source": [
    "## Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ba0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feat =100\n",
    "\n",
    "k_02 = np.linspace(2,5,10)\n",
    "MSE = np.zeros(len(k_02))\n",
    "sources =[]\n",
    "reps = 100\n",
    "var = np.ones(len(yTest))*noiseSD**2\n",
    "llObs = 0\n",
    "m1 = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,u=u,k_0=k_0,R=R) #initiate PDE model\n",
    "\n",
    "def obj_funcVar(x):\n",
    "    llObs = 0\n",
    "    m1.kernel.sigma2=x \n",
    "    m1.sensormodel=sensors\n",
    "    X1 = m1.computeModelRegressors() # Compute regressor matrix\n",
    "    meanZ, covZ = m1.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "    for j in range(reps):\n",
    "        m1.sensormodel=sensors\n",
    "        z = np.random.multivariate_normal(meanZ,covZ)\n",
    "        source = m1.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "        conc=m1.computeConcentration(source) # Compute test concentration\n",
    "        m1.sensormodel=sensorsTest\n",
    "        yInfer= m1.computeObservations() # Compute observations with noise\n",
    "        llObs += -0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "\n",
    "    llObs = llObs/reps\n",
    "    return(-llObs)\n",
    "\n",
    "def obj_funcLength(x):\n",
    "    llObs = 0\n",
    "    m1.kernel.l2=x \n",
    "    m1.sensormodel=sensors\n",
    "    X1 = m1.computeModelRegressors() # Compute regressor matrix\n",
    "    meanZ, covZ = m1.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "    for j in range(reps):\n",
    "        m1.sensormodel=sensors\n",
    "        z = np.random.multivariate_normal(meanZ,covZ)\n",
    "        source = m1.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "        conc=m1.computeConcentration(source) # Compute test concentration\n",
    "        m1.sensormodel=sensorsTest\n",
    "        yInfer= m1.computeObservations() # Compute observations with noise\n",
    "        llObs += -0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "\n",
    "    llObs = llObs/reps\n",
    "    return(-llObs)\n",
    "\n",
    "def obj_funcReact(x):\n",
    "    llObs = 0\n",
    "    m1.R=x \n",
    "    m1.sensormodel=sensors\n",
    "    X1 = m1.computeModelRegressors() # Compute regressor matrix\n",
    "    meanZ, covZ = m1.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "    for j in range(reps):\n",
    "        m1.sensormodel=sensors\n",
    "        z = np.random.multivariate_normal(meanZ,covZ)\n",
    "        source = m1.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "        conc=m1.computeConcentration(source) # Compute test concentration\n",
    "        m1.sensormodel=sensorsTest\n",
    "        yInfer= m1.computeObservations() # Compute observations with noise\n",
    "        llObs += -0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "\n",
    "    llObs = llObs/reps\n",
    "    return(-llObs)\n",
    "\n",
    "def obj_funcDiff(x):\n",
    "    llObs = 0\n",
    "    m1.k_0=x\n",
    "    m1.sensormodel=sensors\n",
    "    X1 = m1.computeModelRegressors() # Compute regressor matrix\n",
    "    meanZ, covZ = m1.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "    for j in range(reps):\n",
    "        m1.sensormodel=sensors\n",
    "        z = np.random.multivariate_normal(meanZ,covZ)\n",
    "        source = m1.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "        conc=m1.computeConcentration(source) # Compute test concentration\n",
    "        m1.sensormodel=sensorsTest\n",
    "        yInfer= m1.computeObservations() # Compute observations with noise\n",
    "        llObs += -0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "\n",
    "    llObs = llObs/reps\n",
    "    return(-llObs)\n",
    "\n",
    "def obj_funcLengthVar(x):\n",
    "    x1 = x[:, 0]\n",
    "    x2 = x[:, 1]\n",
    "    llObs = 0\n",
    "    m1.sensormodel=sensors\n",
    "    m1.kernel.l2=x1\n",
    "    m1.kernel.sigma2=x2\n",
    "    X1 = m1.computeModelRegressors() # Compute regressor matrix\n",
    "    meanZ, covZ = m1.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "    for j in range(reps):\n",
    "        m1.sensormodel=sensors\n",
    "        z = np.random.multivariate_normal(meanZ,covZ)\n",
    "        source = m1.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "        conc=m1.computeConcentration(source) # Compute test concentration\n",
    "        m1.sensormodel=sensorsTest\n",
    "        yInfer= m1.computeObservations() # Compute observations with noise\n",
    "        llObs += -0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "\n",
    "    llObs = llObs/reps\n",
    "    return(-llObs)\n",
    "\n",
    "def obj_funcLengthVarDiffReact(x):\n",
    "    x1 = x[:, 0]\n",
    "    x2 = x[:, 1]\n",
    "    x3 = x[:, 2]\n",
    "    x4 = x[:, 3]\n",
    "    llObs = 0\n",
    "    m1.sensormodel=sensors\n",
    "    m1.kernel.l2=x1\n",
    "    m1.kernel.sigma2=x2\n",
    "    m1.k_0=x3\n",
    "    m1.R=x4\n",
    "    X1 = m1.computeModelRegressors() # Compute regressor matrix\n",
    "    meanZ, covZ = m1.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "    for j in range(reps):\n",
    "        m1.sensormodel=sensors\n",
    "        z = np.random.multivariate_normal(meanZ,covZ)\n",
    "        source = m1.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "        conc=m1.computeConcentration(source) # Compute test concentration\n",
    "        m1.sensormodel=sensorsTest\n",
    "        yInfer= m1.computeObservations() # Compute observations with noise\n",
    "        llObs += -0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "\n",
    "    llObs = llObs/reps\n",
    "    return(-llObs)\n",
    "\n",
    "def obj_funcLengthDiff(x):\n",
    "    x1 = x[:, 0]\n",
    "    x2 = x[:, 1]\n",
    "    llObs = 0\n",
    "    \n",
    "    k = EQ(x1, 2) # generate EQ kernel\n",
    "    m1 = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors16,u=u,k_0=10**x2) #initiate PDE model\n",
    "    X1 = m1.computeModelRegressors() # Compute regressor matrix\n",
    "    meanZ, covZ = m1.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "    for j in range(reps):\n",
    "        m1.sensormodel=sensors\n",
    "        z = np.random.multivariate_normal(meanZ,covZ)\n",
    "        source = m1.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "        conc=m1.computeConcentration(source) # Compute test concentration\n",
    "        m1.sensormodel=sensorsTest\n",
    "        yInfer= m1.computeObservations() # Compute observations with noise\n",
    "        llObs += -0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "\n",
    "    llObs = llObs/reps\n",
    "    return(-llObs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaefffa",
   "metadata": {},
   "source": [
    "# Estimate Kernel Lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667558a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Adjoints...\n",
      "47/48 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "47/48 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "47/48 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "47/48 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "47/48 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "47/48 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "47/48 \n",
      "Calculating Phis...\n",
      "99/100 \n",
      "Calculating Adjoints...\n",
      "47/48 \n",
      "Calculating Phis...\n",
      "99/100 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "domain = [{'name': 'var_1', 'type': 'continuous', 'domain': (1,10)}]\n",
    "\n",
    "\n",
    "myBopt_l = BayesianOptimization(f=obj_funcLength, domain=domain,acquisition_type='EI')\n",
    "myBopt_l.run_optimization(max_iter=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e770478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt_l.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefcb112",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The minumum value obtained by the function was %.4f (x = %.4f)\" % (myBopt_l.fx_opt, myBopt_l.x_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6bd309",
   "metadata": {},
   "source": [
    "# Estimate Kernel Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d31720",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "domain = [{'name': 'var_1', 'type': 'continuous', 'domain': (1,10)}]\n",
    "\n",
    "\n",
    "myBopt_v = BayesianOptimization(f=obj_funcVar, domain=domain)\n",
    "myBopt_v.run_optimization(max_iter=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d96f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt_v.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70165dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The minumum value obtained by the function was %.4f (x = %.4f)\" % (myBopt_v.fx_opt, myBopt_v.x_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28513c34",
   "metadata": {},
   "source": [
    "# Estimate Diffusion Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f83dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "domain = [{'name': 'var_1', 'type': 'continuous', 'domain': (1e-3,1e-1)}]\n",
    "\n",
    "\n",
    "myBopt_d = BayesianOptimization(f=obj_funcDiff, domain=domain)\n",
    "myBopt_d.run_optimization(max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4788fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt_d.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The minumum value obtained by the function was %.4f (x = %.4f)\" % (myBopt_d.fx_opt, myBopt_d.x_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63e3d3",
   "metadata": {},
   "source": [
    "# Estimate Reaction Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = [{'name': 'var_1', 'type': 'continuous', 'domain': (1e-5,10)}]\n",
    "\n",
    "\n",
    "myBopt_R = BayesianOptimization(f=obj_funcReact, domain=domain)\n",
    "myBopt_R.run_optimization(max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "myBopt_R.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The minumum value obtained by the function was %.4f (x = %.4f)\" % (myBopt_R.fx_opt, myBopt_R.x_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7fcd8f",
   "metadata": {},
   "source": [
    "# Infer Entire Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds2d = [{'name': 'var_1', 'type': 'continuous', 'domain': (1,10)},\n",
    "            {'name': 'var_2', 'type': 'continuous', 'domain': (1,10)}]\n",
    "maxiter = 100\n",
    "\n",
    "myBopt_2d = GPyOpt.methods.BayesianOptimization(obj_funcLengthVar, domain=bounds2d)\n",
    "myBopt_2d.run_optimization(max_iter = maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*20)\n",
    "print(\"Value of (x,y) that minimises the objective:\"+str(myBopt_2d.x_opt))    \n",
    "print(\"Minimum value of the objective: \"+str(myBopt_2d.fx_opt))     \n",
    "print(\"=\"*20)\n",
    "myBopt_2d.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093bc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds4d = [{'name': 'var_1', 'type': 'continuous', 'domain': (0.1,10)},\n",
    "            {'name': 'var_2', 'type': 'continuous', 'domain': (0.1,10)},\n",
    "            {'name': 'var_3', 'type': 'continuous', 'domain': (1e-5,1)},\n",
    "            {'name': 'var_4', 'type': 'continuous', 'domain': (0,5)}]\n",
    "maxiter = 10\n",
    "\n",
    "myBopt_4d = GPyOpt.methods.BayesianOptimization(obj_funcLengthVarDiffReact, domain=bounds4d)\n",
    "myBopt_4d.run_optimization(max_iter = maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dab51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*20)\n",
    "print(\"Value of (x,y) that minimises the objective:\"+str(myBopt_4d.x_opt))    \n",
    "print(\"Minimum value of the objective: \"+str(myBopt_4d.fx_opt))     \n",
    "print(\"=\"*20)\n",
    "myBopt_4d.plot_acquisition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158b634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
