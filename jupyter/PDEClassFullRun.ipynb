{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fece61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "\n",
    "#numpy\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal #For later example\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#advectionGP\n",
    "from advectionGP.models import AdjointAdvectionDiffusionReactionModel as Model #Model module builds basic parts of the PDE problem, combines other classes into full model\n",
    "from advectionGP.sensors import FixedSensorModel #Builds sensor arrays to generate data for foward model or to generate observations for comparison\n",
    "from advectionGP.kernels import EQ #Generates exponentiated quadratic kernel approximation\n",
    "from advectionGP.test import TestKernels #Unit test model\n",
    "from advectionGP.wind import WindFixU #Wind model\n",
    "\n",
    "#Plotting tools\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3786e961",
   "metadata": {},
   "source": [
    "# Forward Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "279ebe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sensor locations for training data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(6,98,50) # lower time\n",
    "xloc=np.linspace(6,8,4) # x locations\n",
    "yloc=np.linspace(6,8,4) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "X= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "X[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] #lower time\n",
    "X[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1] # x location\n",
    "X[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2] # ylocation\n",
    "X[:,1] = X[:,0]+1 # upper time\n",
    "\n",
    "sensors = FixedSensorModel(X,1) # establish sensor model arguments are sensor locations and spatial averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c8993af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sensor locations for test data with shape [total observations, 4], where each row has elements \n",
    "#[lower time location, upper time location, x location, y location]\n",
    "\n",
    "tlocL = np.linspace(6,9,5) # lower time\n",
    "xloc=np.linspace(6.5,7.5,4) # x locations\n",
    "yloc=np.linspace(6.5,7.5,4) # y locations\n",
    "sensN = len(xloc)*len(yloc) # total number of sensors \n",
    "obsN = len(tlocL) # total time points at which an observation is taken\n",
    "Xtest= np.zeros((obsN*sensN,4)) # obsN*sensN is total observations over all sensors and all times\n",
    "# Build sensor locations\n",
    "Xtest[:,0] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[0] \n",
    "Xtest[:,2] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[1]\n",
    "Xtest[:,3] = np.asarray(np.meshgrid(tlocL,xloc,yloc)).reshape(3,sensN*obsN)[2]\n",
    "Xtest[:,1] = Xtest[:,0]+1\n",
    "\n",
    "sensorsTest = FixedSensorModel(Xtest,1) # establish sensor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b097b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forward model to generate concentration\n",
    "#u = [0.05,0.] #Advection\n",
    "\n",
    "\n",
    "k_0 = 0.01 #Diffusion\n",
    "R=0.1\n",
    "noiseSD = 0.05 #Observation noise\n",
    "N_feat=2000 # number of features used to approximate ground truth GP\n",
    "boundary = ([5,5,5],[100,10,10])# corners of the grid - in units of space\n",
    "k = EQ(1, 2.0) # generate EQ kernel arguments are lengthscale and variance\n",
    "res = [500,30,30] # grid size for time, x and y\n",
    "wind=np.cos(np.linspace(0,6*np.pi,res[1]))*0.05\n",
    "u=[]\n",
    "u.append(np.ones(res)*wind) #x direction wind\n",
    "u.append(np.ones(res)*0.0) # y direction wind\n",
    "windmodel=WindFixU(u) # establish fixed wind model\n",
    "m = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,windmodel=windmodel,k_0=k_0,R=R) #initiate PDE model to build concentration\n",
    "\n",
    "dt,dx,dy,dx2,dy2,Nt,Nx,Ny = m.getGridStepSize() # useful numbers!\n",
    "\n",
    "z=np.random.normal(0,1.0,N_feat) # Generate z to compute source\n",
    "source=(m.computeSourceFromPhi(z))# Compute source\n",
    "#source[source<0]=0\n",
    "\n",
    "source = np.zeros(m.resolution)\n",
    "##source[0,int(Nx/2)-1,int(Ny/2)-1] = 10.0\n",
    "#source[:,15:25,15:25] = 5\n",
    "#source[:,2:7,2:7] = 25\n",
    "#source[:,7:12,15:20] = 25\n",
    "source[0:10,18:28,10:20] = 25\n",
    "\n",
    "concTrain=m.computeConcentration(source) # Compute concentration - runs advection diffusion forward model\n",
    "yTrain= m.computeObservations() # Compute observations with noise uses m.sensormodel for observation locations\n",
    "concTrainNN=m.computeConcentration(source,enforce_nonnegative=True) # Compute concentration - runs advection diffusion forward model\n",
    "yTrainNN= m.computeObservations() # Compute observations with noise uses m.sensormodel for observation locations\n",
    "\n",
    "m.sensormodel=sensorsTest\n",
    "yTest= m.computeObservations()\n",
    "\n",
    "print(np.min(concTrain))\n",
    "print(np.min(yTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb2183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "###yTrain= m.computeObservations(addNoise='TRUE') # Compute observations with noise uses m.sensormodel for observation locations\n",
    "\n",
    "yTrain-yTrainNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a240f6d",
   "metadata": {},
   "source": [
    "# Inverse Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d238b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feat =500 #Number of features used to infer the source\n",
    "k = EQ(1, 2.0) \n",
    "mInfer = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,windmodel=windmodel,k_0=k_0,R=R) #Initiate new model for inference\n",
    "regress = mInfer.computeModelRegressors() # Compute regressor matrix\n",
    "meanZ, covZ = mInfer.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "sourceInfer = mInfer.computeSourceFromPhi(meanZ) # Generates estimated source using inferred distributio\n",
    "\n",
    "meanZNN, covZNN = mInfer.computeZDistribution(yTrainNN) # Infers z vector mean and covariance\n",
    "sourceInferNN = mInfer.computeSourceFromPhi(meanZNN) # Generates estimated source using inferred distributio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf432d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.square(np.subtract(source,sourceInfer))).mean() #MSE between ground truth and inferred source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb513f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.square(np.subtract(source,sourceInferNN))).mean() #MSE between ground truth and inferred source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80459a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(concTrain[4])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee98c6",
   "metadata": {},
   "source": [
    "## Plot sources for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f938954",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a=np.floor(np.min((np.min(sourceInfer),np.min(source))))\n",
    "b=np.ceil(np.max((np.max(sourceInfer),np.max(source))))\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "fig = plt.figure()\n",
    "\n",
    "ploti = 0\n",
    "for title, data in zip(['Ground Truth Source','Inferred Source','Inferred Source (Non Negative Conc)'],[source,sourceInfer,sourceInferNN]):\n",
    "    for t in [0,250,498]:\n",
    "        ploti+=1\n",
    "        plt.subplot(3,3,ploti)\n",
    "        im1=plt.imshow(data[t], extent=[0,10,0,10],origin='lower') #fix t...\n",
    "        plt.xlabel(\"t=%d\" % t,fontsize=16)\n",
    "        plt.xticks(fontsize=16)\n",
    "        plt.yticks(fontsize=16)\n",
    "        plt.clim(a,b)\n",
    "        \n",
    "        \n",
    "        tick_font_size = 16\n",
    "        if ploti % 3 == 2: plt.title(title, fontsize=16, fontweight='bold')\n",
    "        #if ploti % 3 == 3:\n",
    "        #    plt.colorbar(im1,fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.tight_layout(rect=[0.1, 0.2, 1, 0.95])\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "cbar_ax = fig.add_axes([0.97, 0.52, 0.02, 0.34])\n",
    "cbar=fig.colorbar(im1, cax=cbar_ax,orientation='vertical')\n",
    "#cbar = plt.colorbar(im3,fraction=0.046)\n",
    "tick_font_size = 16\n",
    "cbar.ax.tick_params(labelsize = tick_font_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63bd902",
   "metadata": {},
   "outputs": [],
   "source": [
    "concInfer=mInfer.computeConcentration(sourceInfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.floor(np.min((np.min(concTrain),np.min(concInfer))))\n",
    "b=np.ceil(np.max((np.max(concInfer),np.max(concTrain))))\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "fig = plt.figure()\n",
    "\n",
    "ploti = 0\n",
    "for title, data in zip(['Ground Truth Conc','Inferred Conc'],[concTrain,concInfer]):\n",
    "    for t in [35,250,498]:\n",
    "        ploti+=1\n",
    "        plt.subplot(3,3,ploti)\n",
    "        im1=plt.imshow(data[t], extent=[0,10,0,10],origin='lower') #fix t...\n",
    "        plt.xlabel(\"t=%d\" % t,fontsize=16)\n",
    "        plt.xticks(fontsize=16)\n",
    "        plt.yticks(fontsize=16)\n",
    "        plt.clim(a,b)\n",
    "        \n",
    "        \n",
    "        tick_font_size = 16\n",
    "        if ploti % 3 == 2: plt.title(title, fontsize=16, fontweight='bold')\n",
    "        #if ploti % 3 == 3:\n",
    "        #    plt.colorbar(im1,fraction=0.046, pad=0.04)\n",
    "\n",
    "fig.tight_layout(rect=[0.1, 0.2, 1, 0.95])\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "cbar_ax = fig.add_axes([0.97, 0.52, 0.02, 0.34])\n",
    "cbar=fig.colorbar(im1, cax=cbar_ax,orientation='vertical')\n",
    "#cbar = plt.colorbar(im3,fraction=0.046)\n",
    "tick_font_size = 16\n",
    "cbar.ax.tick_params(labelsize = tick_font_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e45c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_feat =200 #Number of features used to infer the source\n",
    "k = EQ(2, 2.0) \n",
    "mInfer = Model(resolution=res,boundary=boundary,N_feat=N_feat,noiseSD=noiseSD,kernel=k,sensormodel=sensors,windmodel=windmodel,k_0=k_0,R=R) #Initiate new model for inference\n",
    "X1 = mInfer.computeModelRegressors() # Compute regressor matrix\n",
    "meanZ, covZ = mInfer.computeZDistribution(yTrain) # Infers z vector mean and covariance\n",
    "reps=100\n",
    "llObs=0\n",
    "llObsNN=0\n",
    "MSE=0\n",
    "MSENN=0\n",
    "cMSE=0\n",
    "cMSENN=0\n",
    "negPercent=0\n",
    "var = np.ones(len(yTest))*noiseSD**2\n",
    "for j in range(reps):\n",
    "    mInfer.sensormodel=sensors\n",
    "    z = np.random.multivariate_normal(meanZ,covZ)\n",
    "    source = mInfer.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "    conc=mInfer.computeConcentration(source,enforce_nonnegative=True) # Compute test concentration\n",
    "    mInfer.sensormodel=sensorsTest\n",
    "    yInfer= mInfer.computeObservations(addNoise='TRUE') # Compute observations with noise\n",
    "    llObsNN += 0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "    MSENN += (np.square(np.subtract(yTest,yInfer))).mean() \n",
    "    cMSENN += (np.square(np.subtract(conc,concTrain))).mean() \n",
    "llObsNN = llObsNN/reps\n",
    "MSENN = MSENN/reps\n",
    "cMSENN = cMSENN/reps\n",
    "\n",
    "for j in range(reps):\n",
    "    mInfer.sensormodel=sensors\n",
    "    z = np.random.multivariate_normal(meanZ,covZ)\n",
    "    source = mInfer.computeSourceFromPhi(z) # Generates estimated source using inferred distribution\n",
    "    conc=mInfer.computeConcentration(source) # Compute test concentration\n",
    "    if np.min(conc) < 0:\n",
    "        negPercent+=1\n",
    "    mInfer.sensormodel=sensorsTest\n",
    "    yInfer= mInfer.computeObservations(addNoise='TRUE') # Compute observations with noise\n",
    "    llObs += 0.5*np.sum((np.square(np.subtract(yTest,yInfer))/var)+0.5*np.log(var))\n",
    "    MSE += (np.square(np.subtract(yTest,yInfer))).mean() \n",
    "    cMSE += (np.square(np.subtract(conc,concTrain))).mean() \n",
    "llObs = llObs/reps\n",
    "MSE=MSE/reps\n",
    "cMSE=cMSE/repsa\n",
    "print(negPercent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60806797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08798ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "llObsNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da200d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ae07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6bf8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c7452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cMSENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dcd078",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(conc[40])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b591e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(concTrain[40])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87248ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " np.trapz(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bc2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
